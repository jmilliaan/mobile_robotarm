{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b649d12-ae1a-40a8-8808-2084ee378975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D,Flatten,Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33052c5-6b93-40db-897c-0aabc12f7d48",
   "metadata": {},
   "source": [
    "## Define Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01217db0-f049-4e7b-afea-2de5e6be98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine folder with image name\n",
    "\n",
    "def getName(filePath):\n",
    "    myImagePathL = filePath.split('/')[-2:]\n",
    "    myImagePath = os.path.join(myImagePathL[0],myImagePathL[1])\n",
    "    return myImagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4696f072-23d6-475f-95ce-d8acafc75eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the dataframe\n",
    "\n",
    "def importDataInfo(path):\n",
    "    columns = ['Filename','Steering']\n",
    "    noOfFolders = len(os.listdir(path))//2\n",
    "    data = pd.DataFrame()\n",
    "    for x in range(0,4):\n",
    "        if x != 0:\n",
    "            pass\n",
    "        else:\n",
    "            dataNew = pd.read_csv(os.path.join(path, f'log_{x}.csv'), names = columns)\n",
    "            print(f'{x}:{dataNew.shape[0]} ',end='')\n",
    "            #### REMOVE FILE PATH AND GET ONLY FILE NAME\n",
    "            #print(getName(data['center'][0]))\n",
    "            dataNew['Filename']=dataNew['Filename'].apply(getName)\n",
    "            data =data.append(dataNew,True )\n",
    "    print(' ')\n",
    "    print('Total Images Imported',data.shape[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8207aa-d37d-4b61-a5ea-0ac2f5fb6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove high occurence image\n",
    "\n",
    "def balanceData(data,display=True):\n",
    "    nBin = 31\n",
    "    samplesPerBin = 300\n",
    "    hist, bins = np.histogram(data['Steering'], nBin)\n",
    "    if display:\n",
    "        center = (bins[:-1] + bins[1:]) * 0.5\n",
    "        plt.bar(center, hist, width=0.03)\n",
    "        plt.plot((np.min(data['Steering']), np.max(data['Steering'])), (samplesPerBin, samplesPerBin))\n",
    "        plt.title('Data Visualisation')\n",
    "        plt.xlabel('Steering Angle')\n",
    "        plt.ylabel('No of Samples')\n",
    "        plt.show()\n",
    "    removeindexList = []\n",
    "    for j in range(nBin):\n",
    "        binDataList = []\n",
    "        for i in range(len(data['Steering'])):\n",
    "            if data['Steering'][i] >= bins[j] and data['Steering'][i] <= bins[j + 1]:\n",
    "                binDataList.append(i)\n",
    "        binDataList = shuffle(binDataList)\n",
    "        binDataList = binDataList[samplesPerBin:]\n",
    "        removeindexList.extend(binDataList)\n",
    "\n",
    "    print('Removed Images:', len(removeindexList))\n",
    "    data.drop(data.index[removeindexList], inplace=True)\n",
    "    print('Remaining Images:', len(data))\n",
    "    if display:\n",
    "        hist, _ = np.histogram(data['Steering'], (nBin))\n",
    "        plt.bar(center, hist, width=0.03)\n",
    "        plt.plot((np.min(data['Steering']), np.max(data['Steering'])), (samplesPerBin, samplesPerBin))\n",
    "        plt.title('Balanced Data')\n",
    "        plt.xlabel('Steering Angle')\n",
    "        plt.ylabel('No of Samples')\n",
    "        plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d9e871-6aa3-4cc6-892f-70e5808055b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for split train test\n",
    "\n",
    "def loadData(path, data):\n",
    "    imagesPath = []\n",
    "    steering = []\n",
    "    for i in range(len(data)):\n",
    "        indexed_data = data.iloc[i]\n",
    "        imagesPath.append( os.path.join(path,indexed_data[0]))\n",
    "        steering.append(float(indexed_data[1]))\n",
    "    imagesPath = np.asarray(imagesPath)\n",
    "    steering = np.asarray(steering)\n",
    "    return imagesPath, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe1090e-4f98-4cf2-b742-b02942d57936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image augmentation\n",
    "\n",
    "def augmentImage(imgPath,steering):\n",
    "    img =  mpimg.imread(imgPath)\n",
    "    if np.random.rand() < 0.5:\n",
    "        pan = iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
    "        img = pan.augment_image(img)\n",
    "    if np.random.rand() < 0.5:\n",
    "        zoom = iaa.Affine(scale=(1, 1.2))\n",
    "        img = zoom.augment_image(img)\n",
    "    if np.random.rand() < 0.5:\n",
    "        brightness = iaa.Multiply((0.5, 1.2))\n",
    "        img = brightness.augment_image(img)\n",
    "    if np.random.rand() < 0.5:\n",
    "        img = cv2.flip(img, 1)\n",
    "        steering = -steering\n",
    "    return img, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30a4b84-c0d8-4acf-82da-779b2c1c88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate process for train and test data.\n",
    "\n",
    "def dataGen(imagesPath, steeringList, batchSize, trainFlag):\n",
    "    while True:\n",
    "        imgBatch = []\n",
    "        steeringBatch = []\n",
    "\n",
    "        for i in range(batchSize):\n",
    "            index = random.randint(0, len(imagesPath) - 1)\n",
    "            if trainFlag:\n",
    "                img, steering = augmentImage(imagesPath[index], steeringList[index])\n",
    "            else:\n",
    "                img = mpimg.imread(imagesPath[index])\n",
    "                steering = steeringList[index]\n",
    "            img = preProcess(img)\n",
    "            imgBatch.append(img)\n",
    "            steeringBatch.append(steering)\n",
    "        yield (np.asarray(imgBatch),np.asarray(steeringBatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3897ed31-6b3f-42ca-ae8c-ee8264f05729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def preProcess(img):\n",
    "#     img = cv2.imread(filePath) \n",
    "    img = img[54:120,:,:]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    img = cv2.GaussianBlur(img,  (3, 3), 0)\n",
    "    img = cv2.resize(img, (200, 66))\n",
    "    img = img/255\n",
    "    plt.imshow(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6745ba-6e9a-4e6e-947f-363aba17b693",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf4a9205-cd98-4535-b437-e8956c766c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:3305  \n",
      "Total Images Imported 3305\n"
     ]
    }
   ],
   "source": [
    "df = importDataInfo('DataCollected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cfd5998-cdc3-484a-9624-6ec5a12098bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Steering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG0\\Image_1638858271625566.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG0\\Image_1638858272182506.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG0\\Image_1638858272613807.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG0\\Image_1638858273052654.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG0\\Image_1638858273483709.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Filename  Steering\n",
       "0  IMG0\\Image_1638858271625566.jpg       0.0\n",
       "1  IMG0\\Image_1638858272182506.jpg       0.0\n",
       "2  IMG0\\Image_1638858272613807.jpg       0.0\n",
       "3  IMG0\\Image_1638858273052654.jpg       0.0\n",
       "4  IMG0\\Image_1638858273483709.jpg       0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930335a-8581-4e0d-9c31-cd1cff31410f",
   "metadata": {},
   "source": [
    "## Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f847d2c1-32c7-4705-8c73-3c8be05c8817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Images: 2023\n",
      "Remaining Images: 1282\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcf0lEQVR4nO3df7xVdZ3v8ddb/I2mEIjIjw4Z1kVL0hP+nBuOPfx5DZ3JhCljHCe09KZXmyvmXLW6NHYbbZwmu1GZ9MMfNGpS2qh5UacpRCBBgVRUVIQB/AnYiAN+7h/re5bbwz7nrHM4a6/z4/18PPZj7/1d3+9an7U57M/+ftda36WIwMzMDGCHqgMwM7Oew0nBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56Rg/YKkJkkhaceqY2kh6UpJP6k6DrNaTgrWa0haKek/JG2S9IqkOyWNqjquMkiaKOmttK+bJK2SNFvSRzqxDicd6zQnBettTomIPYDhwFrgWxXHU6bVaV/3BA4H/gD8q6Rjqw3L+jInBeuVIuIN4J+BcS1lkk6W9HtJGyQ9L+nKttpLOkvSckkbJT0t6ZyaZRPTL/OLJa2TtEbSWTXLd5N0taRnJb0m6TeSdkvLDpf0W0mvSlosaWJNuzGSHkjbvBcYUnBfIyJWRcTlwPeBr9es89q0rxskLZT0J6n8BOBLwBmpp7G4o/02AycF66Uk7Q6cAcyrKX4d+AywN3Ay8DlJp7axinXAfwPeBZwFfFPSITXL9wX2AkYAZwPfljQoLft74FDgSGAw8D+BtySNAO4E/ncq/yJwq6Shqd2NwEKyZPBVYGoXdv024BBJA9P7h4HxaXs3Aj+TtGtE/AvwNeCWiNgjIg4uuN/Wz8lzH1lvIWkl2RfqFmAPsi+44yPi0Tbq/wPZD+3/IakJeAbYKSK21Kn7c2BuRFybft3/Ctizpa6kdcDHgflkyefwiFjcah2XAAdFxJk1ZXeTfVnPBZ4G9oqI19OyG4G3IuLTdeKZCPwkIka2Kv8AsBwYGREv1Gn3CjAxIhanntL76q2/3n63Vcf6F/cUrLc5NSL2BnYBzgcekLQvgKTDJM2VtF7Sa8C5tDFEI+lESfMkvSzpVeCkVnVfapU8/kiWiIYAuwJP1Vnte4DT09DRq2m9R5Md/9gPeKUlISTPdnLfIeu5BPBq2o+L03DQa2l7e9HOsFSB/bZ+zknBeqWI2BoRtwFbyb54IftFPgcYFRF7Af8XUOu2knYBbiUbBhqWksxd9erW8SLwBrB/nWXPAz+OiL1rHgMj4ipgDTCoZtgHYHSB7bV2GrAoIl5Pxw8uAT4JDEr78VrNfrxjGGA799v6CScF65WUmQQMIhtOgewsnZcj4g1JE4C/aKP5zmQ9jfXAFkknAscV2W5EvAVcD1wjaT9JAyQdkb5wfwKcIun4VL5rOmg9MiKeBRYAX5a0s6SjgVM6sa8jJF0B/DXZAeSW/d2S9mNHSZeTHStosRZoktTy/7zL+239h5OC9Ta/kLQJ2ADMAKZGxNK07PPAVyRtBC4HZtdbQURsBL6Qlr9CljzmdCKGLwKPkh3kfZnsbKAdIuJ5YBLZl/Z6sp7D3/D2/7O/AA5Lba4AftTBdvZL+7opbeuDZMcL7knL7yY79vEE2VDUG2mbLX6Wnl+StKgb9tv6AR9oNjOznHsKZmaWc1IwM7Ock4KZmeWcFMzMLNdjphHuiiFDhkRTU1PVYZiZ9SoLFy58MSKG1lvWq5NCU1MTCxYsqDoMM7NeRVKbV9N7+MjMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZrnSkkKaNnh+uk/tUklfTuWDJd0r6cn0PKimzaWSVkh6XNLxZcVmZmb1ldlT2Az8abo37HjgBEmHA9OB+yJiLHBfeo+kccBk4EDgBOA6SQNKjM/MzFop7eK1yObk3pTe7pQeQTbf/MRUPgu4n+zuUZOAmyNiM/CMpBXABOB3ZcT35V8sZdnqDWWs2sysdOP2exdXnHJgt6+31Cua0y/9hcD7gG9HxEOShkXEGoCIWCNpn1R9BDCvpvmqVNZ6ndOAaQCjR3flboZmnffQMy/XLT9szOAGR2JWrlKTQkRsBcZL2hu4XdJB7VSvd5/Ybe4AFBEzgZkAzc3NXb5DUBkZ1vqupul31i2/5ZwjGhyJWbkacvZRRLxKNkx0ArBW0nCA9LwuVVsFjKppNhJY3Yj4zMwsU+bZR0NTDwFJuwEfA/5Adk/YqanaVOCO9HoOMFnSLpLGAGOB+WXFZ2Zm2ypz+Gg4MCsdV9gBmB0Rv5T0O2C2pLOB54DTASJiqaTZwDJgC3BeGn4yM7MGKfPsoyXAh+uUvwQc20abGcCMsmIyM7P2+YpmMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLlZYUJI2SNFfScklLJV2Qyq+U9IKkR9LjpJo2l0paIelxSceXFZuZmdW3Y4nr3gJcHBGLJO0JLJR0b1r2zYj4+9rKksYBk4EDgf2AX0s6ICK2lhijmZnVKK2nEBFrImJRer0RWA6MaKfJJODmiNgcEc8AK4AJZcVnZmbbasgxBUlNwIeBh1LR+ZKWSLpe0qBUNgJ4vqbZKuokEUnTJC2QtGD9+vVlhm1m1u+UnhQk7QHcClwYERuA7wD7A+OBNcDVLVXrNI9tCiJmRkRzRDQPHTq0nKDNzPqpUpOCpJ3IEsJPI+I2gIhYGxFbI+It4Hu8PUS0ChhV03wksLrM+MzM7J3KPPtIwA+A5RFxTU358JpqpwGPpddzgMmSdpE0BhgLzC8rPjMz21aZZx8dBZwJPCrpkVT2JWCKpPFkQ0MrgXMAImKppNnAMrIzl87zmUdmZo1VWlKIiN9Q/zjBXe20mQHMKCsmMzNrn69oNjOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmluswKUgaKGmH9PoASR+XtFP5oZmZWaMV6Sk8COwqaQRwH3AWcEOZQZmZWTWKJAVFxB+BPwO+FRGnAeM6bCSNkjRX0nJJSyVdkMoHS7pX0pPpeVBNm0slrZD0uKTju7pTZmbWNYWSgqQjgE8Bd6ayHQu02wJcHBH/BTgcOE/SOGA6cF9EjCXreUxPGxkHTAYOBE4ArpM0oDM7Y2Zm26dIUrgQuBS4PSKWSnovMLejRhGxJiIWpdcbgeXACGASMCtVmwWcml5PAm6OiM0R8QywAphQfFfMzGx7dfiLPyIeAB6QNDC9fxr4Qmc2IqkJ+DDwEDAsItakda2RtE+qNgKYV9NsVSprva5pwDSA0aNHdyYMMzPrQJGzj46QtIzslz6SDpZ0XdENSNoDuBW4MCI2tFe1TllsUxAxMyKaI6J56NChRcMwM7MCigwf/QNwPPASQEQsBv5rkZWnU1dvBX4aEbel4rWShqflw4F1qXwVMKqm+UhgdZHtmJlZ9yh08VpEPN+qaGtHbSQJ+AGwPCKuqVk0B5iaXk8F7qgpnyxpF0ljgLHA/CLxmZlZ9yhyFtHzko4EQtLOZMcTlhdodxRwJvCopEdS2ZeAq4DZks4GngNOB0gHsWcDy8jOXDovIjpMPmZm1n2KJIVzgWvJDvquAu4BzuuoUUT8hvrHCQCObaPNDGBGgZjMzKwERc4+epHsGgUzM+vj2kwKkr5FnbN/WkREp05LNTOznq+9nsKChkVhZmY9QptJISJm1b6X9K6sODaWHpWZmVWiyMVrzZIeBZYAj0laLOnQ8kMzM7NGK3L20fXA5yPiXwEkHQ38EPhQmYGZmVnjFbl4bWNLQoD8VFMPIZmZ9UFFegrzJX0XuInsbKQzgPslHQLQMhOqmZn1fkWSwvj0fEWr8iPJksSfdmdAZmZWnSIXrx3TiEDMzKx6HSYFSXsDnwGaauv74jUzs76nyPDRXWQ3v3kUeKvccMzMrEpFksKuEXFR6ZGYmVnlipyS+mNJn5U0XNLglkfpkZmZWcMV6Sm8CXwDuIy3J8gL4L1lBWVmZtUokhQuAt6XptA2M7M+rMjw0VLgj2UHYmZm1SvSU9gKPCJpLrC5pdCnpJqZ9T1FksLP08PMzPq4Ilc0z+qojpmZ9Q1FrmgeC/wdMA7YtaU8Inz2kZlZH1PkQPMPge8AW4BjgB8BPy4zKDMzq0aRpLBbRNwHKCKejYgr8cyoZmZ9UpEDzW9I2gF4UtL5wAvAPuWGZWZmVSjSU7gQ2B34AnAocCYwtcSYzMysIh0mhYh4OCI2RcQqsqub/zwi5nXUTtL1ktZJeqym7EpJL0h6JD1Oqll2qaQVkh6XdHxXd8jMzLquzaQg6XJJH0ivd0kXrz0FrJX0sQLrvgE4oU75NyNifHrcldY/DpgMHJjaXCdpQOd2xczMtld7PYUzgMfT65bhoqHAR4GvdbTiiHgQeLlgHJOAmyNic0Q8A6wAJhRsa2Zm3aS9pPBmRLTMino82Zf21ohYTrED1G05X9KSNLw0KJWNAJ6vqbMqlW1D0jRJCyQtWL9+/XaEYWZmrbWXFDZLOkjSULLrE+6pWbZ7F7f3HWB/YDywBrg6latO3ahTRkTMjIjmiGgeOnRoF8MwM7N62vvFfwHwz2RDRt9Mwzqkg8O/78rGImJty2tJ3wN+md6uAkbVVB0JrO7KNszMrOvaTAoR8RDwgTrld5Hdt7nTJA2PiDXp7WlAy5lJc4AbJV0D7AeMBeZ3ZRtmZtZ123NsoF2SbgImAkMkrQKuACZKGk82NLQSOAcgIpZKmg0sI5tO47yI2FpWbGZmVl9pSSEiptQp/kE79WcAM8qKx8zMOtbedQqnp+cxjQvHzMyq1N7ZR5em51sbEYiZmVWvveGjl9JVzGMkzWm9MCI+Xl5YZmZWhfaSwsnAIWT3Tri6nXpmZtZHtHdK6pvAPElHRsR6SXtmxbGpceGZmVkjFZk6e5ik35NdU7BM0kJJB5Ucl5mZVaBIUpgJXBQR74mI0cDFqczMzPqYIklhYETMbXkTEfcDA0uLyMzMKlPk4rWnJf0vsgPOAJ8GnikvJDMzq0qRnsJfkU2Kd1t6DAHOKjMoMzOrRoc9hYh4hez+zGZm1scV6SmYmVk/4aRgZmY5JwUzM8t1mBQkjZR0u6T1ktZKulXSyEYEZ2ZmjVWkp/BDsjujDQdGAL9IZWZm1scUSQpDI+KHEbElPW4gO0XVzMz6mCJJ4UVJn5Y0ID0+DbxUdmBmZtZ4RS9e+yTw78Aa4BOpzMzM+pgiF689B/iGOmZm/UCbSUHS5e20i4j4agnxmJlZhdrrKbxep2wgcDbwbsBJwcysj2nvzmv5LTjTXdcuIJsI72Z8e04zsz6p3WMKkgYDFwGfAmYBh6QJ8szMrA9q75jCN4A/I7vL2gd9b2Yzs76vvVNSLwb2A/4WWC1pQ3pslLShMeGZmVkjtZkUImKHiNgtIvaMiHfVPPaMiHd1tGJJ10taJ+mxmrLBku6V9GR6HlSz7FJJKyQ9Lun47d81MzPrrCK34+yqG4B/An5UUzYduC8irpI0Pb2/RNI4YDJwIFnv5NeSDoiIrSXGZ9btmqbfuU3ZyqtOriASs64pbersiHgQeLlV8SSyA9ak51Nrym+OiM0R8QywAphQVmxmZlZfo++nMCwi1gCk531S+Qjg+Zp6q1LZNiRNk7RA0oL169eXGqyZWX/TU26yozplUa9iRMyMiOaIaB461JO1mpl1p0YnhbWShgOk53WpfBUwqqbeSGB1g2MzM+v3Gp0U5gBT0+upwB015ZMl7SJpDDAWmN/g2MzM+r3Szj6SdBMwERgiaRVwBXAVMFvS2cBzwOkAEbFU0mxgGbAFOM9nHpmZNV5pSSEiprSx6Ng26s8AZpQVj5mZdaynHGg2M7MewEnBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmudLup9CbNE2/c5uylVedXEEkZmbVck/BzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws57OPzCrgM96sp3JPwczMcu4pWJ/lX+NmneeegpmZ5SrpKUhaCWwEtgJbIqJZ0mDgFqAJWAl8MiJeqSI+M7P+qsqewjERMT4imtP76cB9ETEWuC+9NzOzBupJxxQmARPT61nA/cAlVQVj1hP4uIg1WlVJIYB7JAXw3YiYCQyLiDUAEbFG0j71GkqaBkwDGD16dKPirYy/FMyskapKCkdFxOr0xX+vpD8UbZgSyEyA5ubmKCtAM7P+qJJjChGxOj2vA24HJgBrJQ0HSM/rqojNzKw/a3hPQdJAYIeI2JheHwd8BZgDTAWuSs93NDo2q5aHysyqV8Xw0TDgdkkt278xIv5F0sPAbElnA88Bp1cQm5lZv9bwpBARTwMH1yl/CTi20fF0t3q/dsG/eK1c7mVZd/EVzWZmlnNSMDOznJOCmZnletIVzWaFePzcrDxOCp3gLyMz6+s8fGRmZjknBTMzy3n4qI/o7qEtD5WZVauqa56cFKx0TjB9k/9d+yYPH5mZWc49BevXPC2J2Ts5KZj1E06AVoSTQj/jcWAza4+PKZiZWc5JwczMch4+MjPrJn1heNY9BTMzy7mnYGZ9TtEzrfrCL/vu5qRgZu9Q1Relv6B7Bg8fmZlZzj2FivhCIusv3APoXZwUrMuc2My6picnSg8fmZlZzj0FM+s1quqd9uRf9t3NPQUzM8s5KZiZWa7HJQVJJ0h6XNIKSdOrjsfMrD/pUUlB0gDg28CJwDhgiqRx1UZlZtZ/9KikAEwAVkTE0xHxJnAzMKnimMzM+g1FRNUx5CR9AjghIv46vT8TOCwizq+pMw2Ylt6+H3i84YHCEODFCrbbVY63XL0tXuh9MTve7vWeiBhab0FPOyVVdcrekbUiYiYwszHh1CdpQUQ0VxlDZzjecvW2eKH3xex4G6enDR+tAkbVvB8JrK4oFjOzfqenJYWHgbGSxkjaGZgMzKk4JjOzfqNHDR9FxBZJ5wN3AwOA6yNiacVh1VPp8FUXON5y9bZ4offF7HgbpEcdaDYzs2r1tOEjMzOrkJOCmZnlnBTqkDRY0r2SnkzPg+rUeb+kR2oeGyRdmJZdKemFmmUn9YSYU72Vkh5NcS3obPtGxitplKS5kpZLWirpgpplDfmMO5p2RZl/TMuXSDqkaNuK4v1UinOJpN9KOrhmWd2/jYrjnSjptZp/58uLtq0w5r+pifcxSVslDU7LGv4Zd1pE+NHqAfwfYHp6PR34egf1BwD/TnZBCMCVwBd7YszASmDI9u5zI+IFhgOHpNd7Ak8A4xr1Gad/16eA9wI7A4tbtl9T5yTgV2TX2BwOPFS0bUXxHgkMSq9PbIm3vb+NiuOdCPyyK22rirlV/VOA/1fVZ9yVh3sK9U0CZqXXs4BTO6h/LPBURDxbZlAd6GzM3d2+szrcXkSsiYhF6fVGYDkwouS4ahWZdmUS8KPIzAP2ljS8YNuGxxsRv42IV9LbeWTXAlVlez6jqqbE6ex2pwA3NSCubuOkUN+wiFgD2RcTsE8H9Sez7T/8+amLfn3ZQzFJ0ZgDuEfSwjRlSGfbd5dObU9SE/Bh4KGa4rI/4xHA8zXvV7FtUmqrTpG23a2z2zybrJfToq2/jbIUjfcISYsl/UrSgZ1s290Kb1fS7sAJwK01xY3+jDutR12n0EiSfg3sW2fRZZ1cz87Ax4FLa4q/A3yV7A/gq8DVwF91LdJ3bKs7Yj4qIlZL2ge4V9IfIuLB7Y2tnm78jPcg+491YURsSMWlfMatN12nrPU53G3VKdK2uxXepqRjyJLC0TXFDfvbaAmjTlnreBeRDctuSseNfg6MLdi2DJ3Z7inAv0XEyzVljf6MO63fJoWI+FhbyyStlTQ8ItakoYB17azqRGBRRKytWXf+WtL3gF/2lJgjYnV6XifpdrLu8INAZ/a5YfFK2oksIfw0Im6rWXcpn3ErRaZdaavOzgXadrdC08RI+hDwfeDEiHippbydv43K4q35EUBE3CXpOklDirQtSWe2u80IQgWfcad5+Ki+OcDU9HoqcEc7dbcZM0xfci1OAx7r1ujq6zBmSQMl7dnyGjiuJrbO7HN3KBKvgB8AyyPimlbLGvEZF5l2ZQ7wmXQW0uHAa2k4rIopWzrcpqTRwG3AmRHxRE15e38bVca7b/o7QNIEsu+sl4q0rSrmFOtewEep+buu6DPuvKqPdPfEB/Bu4D7gyfQ8OJXvB9xVU293sj/QvVq1/zHwKLCE7A9meE+ImeyMicXpsRS4rKP2Fcd7NFnXfAnwSHqc1MjPmOzsoifIzji5LJWdC5ybXovsxlBPpXia22vbgL+DjuL9PvBKzee5oKO/jYrjPT/Fs5jswPiRVX6+RWJO7/8SuLlVu0o+484+PM2FmZnlPHxkZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1KwPkPSZcpmU12SZqE8LJVfmKYc6K7tnCvpM924vqGS/lPSOdu5niZJPe+8d+tVfEqq9QmSjgCuASZGxOZ01evOkU0psJLs+oEXu2E7O0bElu1dT6t1fp7sIsitETFxO9bTRDaj6EHdFJr1Q+4pWF8xHHgxIjYDRMSLKSF8geyCuLmS5gJIOk7S7yQtkvSzNLcSkg6V9ECarOzulqumJd0v6WuSHgAuUHYvhy/WLPu6pPmSnpD0J6l8d0mzU6/lFkkPSWpuI/YpwMXASEn55GqSNkmaoWwyuHmShqXy/dP7hyV9RdKm1iuUNEDSN1KdJdvbC7H+w0nB+op7gFHpi/k6SR8FiIh/JJub5piIOCb1IP4W+FhEHAIsAC5Kcyx9C/hERBwKXA/MqFn/3hHx0Yi4us62d4yICcCFwBWp7PPAKxHxIbIJ+w6tF7SkUcC+ETEfmA2cUbN4IDAvIg4mmx/ns6n8WuDaiPgIbc+7czbZlBsfAT4CfFbSmDbqmuWcFKxPiIhNZF+804D1wC2S/rJO1cOBccC/SXqEbN6l9wDvBw4im7nyEbLEUXuvgVva2XzLRH0Lgab0+miyufaJiMfIpuOoZzJZMiDVn1Kz7E3enuivdt1HAD9Lr29sY73Hkc3J9AjZdOPvJptd1Kxd/XaWVOt7ImIrcD9wv6RHyb7wb2hVTcC9ETHlHYXSB4GlEXFEG6t/vZ1Nb07PW3n7/1S9KZbrmQIMk/Sp9H4/SWMj4kngP+Ptg3616y5CwH+PiLs70cbMPQXrG5TdM7v2l/B4oOVOeBvJbucJ2aRqR0l6X2q3u6QDgMeBoemANZJ20ts3dOmK3wCfTOsaB3ywXszAwIgYERFNEdEE/B1Z76E984A/T6/bqns38Lk0LIakA9LMnGbtclKwvmIPYJakZZKWkA0RXZmWzQR+JWluRKwnm8HyplRvHvCByG6t+Ang65IWk80geuR2xHMdWZJZAlxCNnz0Wqs6U4DbW5XdyjuHkOq5kOw4yHyyA+yt1wvZbKjLgEXpNNXv4pEBK8CnpJqVQNIAYKeIeEPS/mTTgx+Qks/2rnt34D8iIiRNBqZERCPuT2z9gH85mJVjd7LTYHciG9//XHckhORQ4J/SzWdepftvQ2r9mHsKZmaW8zEFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOz3P8H7tgjwF182qsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_balanced = balanceData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79e07b1f-ac5d-4bb3-84b3-f97a478d6fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Steering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG0\\Image_1638858272182506.jpg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG0\\Image_1638858272613807.jpg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IMG0\\Image_1638858275655949.jpg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IMG0\\Image_1638858276089205.jpg</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IMG0\\Image_1638858276955066.jpg</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>IMG0\\Image_1638858476885574.jpg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>IMG0\\Image_163885847694729.jpg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>IMG0\\Image_163885847710798.jpg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>IMG0\\Image_1638858477622406.jpg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3304</th>\n",
       "      <td>IMG0\\Image_1638858477648251.jpg</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1282 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Filename  Steering\n",
       "1     IMG0\\Image_1638858272182506.jpg      0.00\n",
       "2     IMG0\\Image_1638858272613807.jpg      0.00\n",
       "9     IMG0\\Image_1638858275655949.jpg      0.00\n",
       "10    IMG0\\Image_1638858276089205.jpg      0.26\n",
       "12    IMG0\\Image_1638858276955066.jpg      0.21\n",
       "...                               ...       ...\n",
       "3281  IMG0\\Image_1638858476885574.jpg      0.00\n",
       "3283   IMG0\\Image_163885847694729.jpg      0.00\n",
       "3288   IMG0\\Image_163885847710798.jpg      0.00\n",
       "3303  IMG0\\Image_1638858477622406.jpg      0.00\n",
       "3304  IMG0\\Image_1638858477648251.jpg      0.00\n",
       "\n",
       "[1282 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b852b2f-d13c-4e93-941d-85ec6aae23df",
   "metadata": {},
   "source": [
    "# Optional Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f786d17c-5c0d-4712-9909-64fad5527867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to categorize into 3 class\n",
    "df_balanced.loc[df_balanced['Steering'] > 0, 'C_Steering'] = 0.25\n",
    "df_balanced.loc[df_balanced['Steering'] < 0, 'C_Steering'] = -0.25\n",
    "df_balanced.loc[df_balanced['Steering'] == 0, 'C_Steering'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a7706a8-32ce-4d3a-9c62-11ec9eec40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of 3 class\n",
    "X = df_balanced[\"Filename\"]\n",
    "y = df_balanced[\"C_Steering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b6256-1897-44c5-942c-bc9ff0cf84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check path\n",
    "\n",
    "# import pathlib\n",
    "# pathlib.Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3da8f-845a-477b-be71-341e92c7683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check preProcess image result\n",
    "\n",
    "# preProcess(\"C:\\MLCourse\\MLCourse\\self_driving_raspberry\\DataCollected\\IMG0\\Image_163877726896649.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d8cb5-03a2-4644-8565-8e2dc670dfe5",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c824a96-ef6c-4317-a602-5996b5141c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath, steering = loadData(\"C:\\MLCourse\\MLCourse\\self_driving_raspberry\\DataCollected\", df_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7003e990-f3d5-4d71-a328-ba8a16d4ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imagePath, steering,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26be2123-baec-4eaf-b4b4-7eb5d1b2053b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C:\\\\MLCourse\\\\MLCourse\\\\self_driving_raspberry\\\\DataCollected\\\\IMG0\\\\Image_1638858343666732.jpg',\n",
       "       'C:\\\\MLCourse\\\\MLCourse\\\\self_driving_raspberry\\\\DataCollected\\\\IMG0\\\\Image_1638858467643168.jpg',\n",
       "       'C:\\\\MLCourse\\\\MLCourse\\\\self_driving_raspberry\\\\DataCollected\\\\IMG0\\\\Image_1638858378430155.jpg',\n",
       "       ...,\n",
       "       'C:\\\\MLCourse\\\\MLCourse\\\\self_driving_raspberry\\\\DataCollected\\\\IMG0\\\\Image_1638858337993331.jpg',\n",
       "       'C:\\\\MLCourse\\\\MLCourse\\\\self_driving_raspberry\\\\DataCollected\\\\IMG0\\\\Image_1638858399273017.jpg',\n",
       "       'C:\\\\MLCourse\\\\MLCourse\\\\self_driving_raspberry\\\\DataCollected\\\\IMG0\\\\Image_1638858426402031.jpg'],\n",
       "      dtype='<U89')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad0dd26a-4f00-4c15-ae27-77478736b710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33, -0.68,  0.23, ..., -0.52, -0.  ,  0.05])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef2c7b-2e3e-465b-a678-59b6bfd2fe1f",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2971be7b-f9a0-46cc-a333-b14f8f4ec87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(24, (5, 5), (2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
    "model.add(Convolution2D(36, (5, 5), (2, 2), activation='elu'))\n",
    "model.add(Convolution2D(48, (5, 5), (2, 2), activation='elu'))\n",
    "model.add(Convolution2D(64, (3, 3), activation='elu'))\n",
    "model.add(Convolution2D(64, (3, 3), activation='elu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = 'elu'))\n",
    "model.add(Dense(50, activation = 'elu'))\n",
    "model.add(Dense(10, activation = 'elu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(Adam(lr=0.0001),loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12a271-99d9-46b5-953a-518b3205737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.1208 - val_loss: 0.0953\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.1041 - val_loss: 0.0911\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 81s 814ms/step - loss: 0.0980 - val_loss: 0.0924\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 85s 845ms/step - loss: 0.0961 - val_loss: 0.0940\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 100s 998ms/step - loss: 0.0948 - val_loss: 0.0976\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 98s 982ms/step - loss: 0.0909\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 15.1 MiB for an array with shape (50, 66, 200, 3) and data type float64\nTraceback (most recent call last):\n\n  File \"E:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"E:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_15460\\2546521958.py\", line 16, in dataGen\n    yield (np.asarray(imgBatch),np.asarray(steeringBatch))\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.1 MiB for an array with shape (50, 66, 200, 3) and data type float64\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 15.1 MiB for an array with shape (50, 66, 200, 3) and data type float64\nTraceback (most recent call last):\n\n  File \"E:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"E:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_15460\\2546521958.py\", line 16, in dataGen\n    yield (np.asarray(imgBatch),np.asarray(steeringBatch))\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.1 MiB for an array with shape (50, 66, 200, 3) and data type float64\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_1537]\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15460\\3532730206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataGen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                   validation_steps=50)\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m                       \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                       \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m                       total_epochs=1)\n\u001b[0m\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m    397\u001b[0m                                  prefix='val_')\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 15.1 MiB for an array with shape (50, 66, 200, 3) and data type float64\nTraceback (most recent call last):\n\n  File \"E:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"E:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_15460\\2546521958.py\", line 16, in dataGen\n    yield (np.asarray(imgBatch),np.asarray(steeringBatch))\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.1 MiB for an array with shape (50, 66, 200, 3) and data type float64\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 15.1 MiB for an array with shape (50, 66, 200, 3) and data type float64\nTraceback (most recent call last):\n\n  File \"E:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"E:\\Anaconda\\envs\\TF2.2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_15460\\2546521958.py\", line 16, in dataGen\n    yield (np.asarray(imgBatch),np.asarray(steeringBatch))\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.1 MiB for an array with shape (50, 66, 200, 3) and data type float64\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_1537]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataGen(X_train, y_train, 100, 1),\n",
    "                                  steps_per_epoch=100,\n",
    "                                  epochs=10,\n",
    "                                  validation_data=dataGen(X_test, y_test, 50, 0),\n",
    "                                  validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b88939-3284-4131-86fc-9ef20ec8800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d45f7ee-8b79-4940-9e02-56d79df91366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "model.save('Trained_model_V2-1.h5')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e5d7dd6-49b6-4041-805d-6d606ec80c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4cde45-450f-4be1-8d75-b073fb4af006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9194481d-9023-4e78-b71f-ac14bc8fe785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8edd0-afe8-4878-b326-4ca26dd35b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.1",
   "language": "python",
   "name": "tf2.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
